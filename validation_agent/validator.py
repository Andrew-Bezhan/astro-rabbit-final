"""
–ê–≥–µ–Ω—Ç-–≤–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–º–ø—Ç–∞–º
"""

import re
import json
import traceback
from typing import Dict, Any, List, Tuple, Optional
from utils.logger import setup_logger

logger = setup_logger()

# --- BEGIN SAFE LOGGING HELPERS ---
def _safe_json(obj) -> str:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç –ª—é–±–æ–π –æ–±—ä–µ–∫—Ç –¥–ª—è –ª–æ–≥–∞, –Ω–µ —Ä–æ–Ω—è—è –ª–æ–≥–≥–µ—Ä."""
    try:
        if isinstance(obj, str):
            # –ø–æ–ø—ã—Ç–∫–∞ –≤—ã—Ç–∞—â–∏—Ç—å JSON –∏–∑ ¬´–≥—Ä—è–∑–Ω–æ–π¬ª —Å—Ç—Ä–æ–∫–∏ –∏ –∫—Ä–∞—Å–∏–≤–æ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å
            obj_str = obj.strip()
            if obj_str.startswith("{") and obj_str.endswith("}"):
                return json.dumps(json.loads(obj_str), ensure_ascii=False, indent=2)
            return obj
        return json.dumps(obj, ensure_ascii=False, indent=2)
    except Exception:
        try:
            return str(obj)
        except Exception:
            return "<unprintable>"

def log_kv(level: str, msg: str, payload=None):
    """–õ–æ–≥ —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–æ–π. –ù–∏–∫–∞–∫–∏—Ö f-—Å—Ç—Ä–æ–∫/format/%."""
    safe_payload = _safe_json(payload)
    if level == "error":
        logger.error(msg + " | data=" + safe_payload)
    elif level == "warning":
        logger.warning(msg + " | data=" + safe_payload)
    elif level == "info":
        logger.info(msg + " | data=" + safe_payload)
    else:
        logger.debug(msg + " | data=" + safe_payload)
# --- END SAFE LOGGING HELPERS ---


class PromptValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø—Ä–æ–º–ø—Ç–∞–º"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞"""
        self.validation_rules = {
            'no_html_tags': self._check_no_html_tags,
            'no_markdown': self._check_no_markdown,
            'has_emojis': self._check_has_emojis,
            'proper_structure': self._check_proper_structure,
            'no_hash_symbols': self._check_no_hash_symbols,
            'required_emoji_sections': self._check_required_emoji_sections,
            'graphic_icons_not_bullets': self._check_graphic_icons_not_bullets,
            'astro_symbols_usage': self._check_astro_symbols_usage,
            'russian_language': self._check_russian_language,
            'no_source_mentions': self._check_no_source_mentions,
            'professional_tone': self._check_professional_tone,
            'no_direct_financial_advice': self._check_no_direct_financial_advice,
            'news_context_usage': self._check_news_context_usage,
            'company_examples': self._check_company_examples
        }
    
    def validate_text(self, text: str, analysis_type: str = "zodiac") -> Tuple[bool, List[str]]:
        """
        –°–¢–†–û–ì–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–º–ø—Ç–∞–º —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
        
        Args:
            text (str): –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            analysis_type (str): –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Tuple[bool, List[str]]: (–≤–∞–ª–∏–¥–µ–Ω –ª–∏ —Ç–µ–∫—Å—Ç, —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–æ–π)
        """
        errors = []
        score = 10.0  # –ù–∞—á–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        
        # –ü–æ–¥—Ä–æ–±–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∞–≤–∏–ª–∞ —Å –≤—ã—á–µ—Ç–æ–º –±–∞–ª–ª–æ–≤
        for rule_name, rule_func in self.validation_rules.items():
            try:
                is_valid, error_msg = rule_func(text)
                if not is_valid:
                    # –í—ã—á–∏—Ç–∞–µ–º –±–∞–ª–ª—ã –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏—è
                    penalty = self._get_penalty_for_rule(rule_name)
                    score -= penalty
                    errors.append(f"{rule_name} (-{penalty} –±–∞–ª–ª–æ–≤): {error_msg}")
            except Exception as e:
                score -= 1.0
                errors.append(f"{rule_name} (–æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏, -1 –±–∞–ª–ª): {e}")
        
        # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É 1.0
        score = max(1.0, score)
        is_valid = score >= 7.0  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
        
        if not is_valid:
            logger.warning("‚ö†Ô∏è –û–°–ù–û–í–ù–û–ô –ê–ì–ï–ù–¢ –ù–ï –°–û–ë–õ–Æ–î–ê–ï–¢ –ü–†–û–ú–ü–¢ (%s): –û—Ü–µ–Ω–∫–∞ %.1f/10", analysis_type, score)
            logger.warning("üìã –°–ø–∏—Å–æ–∫ –Ω–∞—Ä—É—à–µ–Ω–∏–π: %s", errors[:5])  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –æ—à–∏–±–æ–∫
        else:
            logger.info("‚úÖ –¢–µ–∫—Å—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–æ–º–ø—Ç—É (%s): –û—Ü–µ–Ω–∫–∞ %.1f/10", analysis_type, score)
        
        return is_valid, errors
    
    def _get_penalty_for_rule(self, rule_name: str) -> float:
        """–ü–æ–ª—É—á–∏—Ç—å —à—Ç—Ä–∞—Ñ –≤ –±–∞–ª–ª–∞—Ö –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª–∞"""
        penalty_map = {
            'no_html_tags': 3.0,              # –ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è Telegram
            'no_markdown': 3.0,               # –ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è Telegram  
            'required_emoji_sections': 3.0,   # –ö—Ä–∏—Ç–∏—á–Ω–æ - –æ—Å–Ω–æ–≤–Ω—ã–µ –±–ª–æ–∫–∏ –∏–∑ –ø—Ä–æ–º–ø—Ç–∞
            'news_context_usage': 2.5,        # –ö—Ä–∏—Ç–∏—á–Ω–æ - —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
            'company_examples': 2.0,          # –ö—Ä–∏—Ç–∏—á–Ω–æ - —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
            'no_hash_symbols': 2.0,           # –ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è Telegram
            'graphic_icons_not_bullets': 2.0, # –í–∞–∂–Ω–æ –¥–ª—è –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è
            'proper_structure': 2.0,          # –í–∞–∂–Ω–æ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            'russian_language': 2.0,          # –í–∞–∂–Ω–æ –¥–ª—è —Ü–µ–ª–µ–≤–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏
            'has_emojis': 1.5,               # –í–∞–∂–Ω–æ –¥–ª—è –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è
            'no_source_mentions': 1.5,        # –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–∏–∑–º
            'astro_symbols_usage': 1.0,       # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ
            'professional_tone': 1.0,         # –°—Ç–∏–ª—å
            'no_direct_financial_advice': 1.0  # –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
        }
        return penalty_map.get(rule_name, 1.0)
    
    def _check_no_html_tags(self, text: str) -> Tuple[bool, str]:
        """–°–¢–†–û–ì–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è HTML-—Ç–µ–≥–æ–≤ (–ö–†–ò–¢–ò–ß–ù–û –¥–ª—è Telegram)"""
        # –ó–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ HTML —Ç–µ–≥–∏ (–≤–∫–ª—é—á–∞—è <b> –∏ <i> - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç)
        forbidden_tags = re.findall(r'<[^>]+>', text)
        if forbidden_tags:
            unique_tags = list(set(forbidden_tags))
            return False, f"–ö–†–ò–¢–ò–ß–ù–û: –ù–∞–π–¥–µ–Ω—ã HTML-—Ç–µ–≥–∏: {unique_tags[:10]} (–≤—Å–µ–≥–æ: {len(forbidden_tags)})"
        return True, ""
    
    def _check_no_markdown(self, text: str) -> Tuple[bool, str]:
        """–°–¢–†–û–ì–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è Markdown (–ö–†–ò–¢–ò–ß–ù–û –¥–ª—è Telegram)"""
        markdown_violations = []
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã Markdown
        markdown_patterns = [
            (r'\*\*[^*]+\*\*', '**–∂–∏—Ä–Ω—ã–π**'),      # **–∂–∏—Ä–Ω—ã–π**
            (r'__[^_]+__', '__–∂–∏—Ä–Ω—ã–π__'),          # __–∂–∏—Ä–Ω—ã–π__
            (r'\*[^*\s]+[^*]*\*', '*–∫—É—Ä—Å–∏–≤*'),     # *–∫—É—Ä—Å–∏–≤*
            (r'_[^_\s]+[^_]*_', '_–∫—É—Ä—Å–∏–≤_'),       # _–∫—É—Ä—Å–∏–≤_
            (r'^#{1,6}\s', '# –∑–∞–≥–æ–ª–æ–≤–∫–∏'),         # # –∑–∞–≥–æ–ª–æ–≤–∫–∏
            (r'^---+', '--- —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏'),         # --- —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
            (r'^\*\s', '* —Å–ø–∏—Å–∫–∏'),               # * —Å–ø–∏—Å–∫–∏  
            (r'^-\s', '- —Å–ø–∏—Å–∫–∏'),                # - —Å–ø–∏—Å–∫–∏
            (r'^\+\s', '+ —Å–ø–∏—Å–∫–∏'),               # + —Å–ø–∏—Å–∫–∏
        ]
        
        for pattern, description in markdown_patterns:
            matches = re.findall(pattern, text, re.MULTILINE)
            if matches:
                markdown_violations.extend([f"{description}: {m[:50]}..." for m in matches[:3]])
        
        if markdown_violations:
            return False, f"–ö–†–ò–¢–ò–ß–ù–û: –ù–∞–π–¥–µ–Ω Markdown: {markdown_violations[:5]}"
        
        return True, ""
    
    def _check_has_emojis(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —ç–º–æ–¥–∑–∏"""
        emoji_pattern = r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002600-\U000027BF\U0001F900-\U0001F9FF]'
        emojis = re.findall(emoji_pattern, text)
        
        if len(emojis) < 5:
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —ç–º–æ–¥–∑–∏: {len(emojis)} (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 5)"
        
        return True, ""
    
    def _check_proper_structure(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ —Å —ç–º–æ–¥–∑–∏
        required_sections = ['üåü', 'üíé', 'üöÄ', '‚ö†Ô∏è']
        found_sections = []
        
        for section in required_sections:
            if section in text:
                found_sections.append(section)
        
        if len(found_sections) < 3:
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {found_sections} (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 3 –∏–∑ {required_sections})"
        
        return True, ""
    
    def _check_no_hash_symbols(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Å–∏–º–≤–æ–ª–æ–≤ #"""
        if '#' in text:
            hash_lines = [line.strip() for line in text.split('\n') if '#' in line]
            return False, f"–ù–∞–π–¥–µ–Ω—ã —Å–∏–º–≤–æ–ª—ã #: {hash_lines[:3]}"
        
        return True, ""
    
    def _check_required_emoji_sections(self, text: str) -> Tuple[bool, str]:
        """–°–¢–†–û–ì–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö 6 –±–ª–æ–∫–æ–≤ –∏–∑ prompts.py"""
        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ –¢–û–ß–ù–û –∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ –≤ COMPANY_ZODIAC_PROMPT
        required_blocks = [
            ('üåü', '–í–õ–ò–Ø–ù–ò–ï –ó–ù–ê–ö–ê –ó–û–î–ò–ê–ö–ê –ù–ê –°–£–î–¨–ë–£', 300),
            ('üîÆ', '–í–õ–ò–Ø–ù–ò–ï –ü–õ–ê–ù–ï–¢ –ò –ú–ï–°–¢–ê –†–ï–ì–ò–°–¢–†–ê–¶–ò–ò', 250),
            ('üíé', '–°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´ –ò –ü–û–¢–ï–ù–¶–ò–ê–õ –†–û–°–¢–ê', 300),
            ('üßò', '–§–ò–õ–û–°–û–§–°–ö–ê–Ø –ö–û–ù–¶–ï–ü–¶–ò–Ø –ö–û–ú–ü–ê–ù–ò–ò', 250),
            ('‚ö†Ô∏è', '–ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ï –†–ò–°–ö–ò –ò –í–´–ó–û–í–´', 200),
            ('üíº', '–ë–ò–ó–ù–ï–°-–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ò –°–¢–†–ê–¢–ï–ì–ò–ò', 200)
        ]
        
        missing_blocks = []
        insufficient_blocks = []
        
        for emoji, block_name, min_words in required_blocks:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —ç–º–æ–¥–∑–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ –±–ª–æ–∫–∞
            block_pattern = rf'{re.escape(emoji)}\s+[^\\n]*{re.escape(block_name.split()[0])}'
            block_match = re.search(block_pattern, text, re.IGNORECASE)
            
            if not block_match:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Å—Ç–æ –Ω–∞–ª–∏—á–∏–µ —ç–º–æ–¥–∑–∏
                if emoji not in text:
                    missing_blocks.append(f"{emoji} {block_name}")
                else:
                    missing_blocks.append(f"{emoji} {block_name} (–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫)")
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º –±–ª–æ–∫–∞ (–ø—Ä–∏–º–µ—Ä–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
                # –ù–∞—Ö–æ–¥–∏–º –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü –±–ª–æ–∫–∞
                start_pos = block_match.end()
                # –ò—â–µ–º —Å–ª–µ–¥—É—é—â–∏–π –±–ª–æ–∫ –∏–ª–∏ –∫–æ–Ω–µ—Ü —Ç–µ–∫—Å—Ç–∞
                next_block_pattern = r'üåü|üîÆ|üíé|üßò|‚ö†Ô∏è|üíº'
                next_match = re.search(next_block_pattern, text[start_pos:])
                
                if next_match:
                    block_text = text[start_pos:start_pos + next_match.start()]
                else:
                    block_text = text[start_pos:]
                
                word_count = len(block_text.split())
                if word_count < min_words * 0.7:  # –î–æ–ø—É—Å–∫–∞–µ–º 30% –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
                    insufficient_blocks.append(f"{emoji} {block_name} ({word_count} —Å–ª–æ–≤, –Ω—É–∂–Ω–æ {min_words}+)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–∏–π –æ–±—ä–µ–º
        total_words = len(text.split())
        errors = []
        
        if missing_blocks:
            errors.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –±–ª–æ–∫–∏: {missing_blocks}")
        
        if insufficient_blocks:
            errors.append(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –æ–±—ä–µ–º –±–ª–æ–∫–æ–≤: {insufficient_blocks}")
            
        if total_words < 1200:  # –ú–∏–Ω–∏–º—É–º –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            errors.append(f"–û–±—â–∏–π –æ–±—ä–µ–º {total_words} —Å–ª–æ–≤ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–µ–Ω (–Ω—É–∂–Ω–æ 1500+ —Å–ª–æ–≤)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –±–ª–æ–∫–æ–≤
        emoji_order = ['üåü', 'üîÆ', 'üíé', 'üßò', '‚ö†Ô∏è', 'üíº']
        found_positions = []
        
        for emoji in emoji_order:
            pos = text.find(emoji)
            if pos != -1:
                found_positions.append((emoji, pos))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏ –∏–¥—É—Ç –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        if len(found_positions) > 1:
            sorted_positions = sorted(found_positions, key=lambda x: x[1])
            expected_order = [emoji for emoji, _ in sorted_positions]
            actual_order = [emoji for emoji in emoji_order if emoji in expected_order]
            
            if expected_order != actual_order:
                errors.append(f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –±–ª–æ–∫–æ–≤: –Ω–∞–π–¥–µ–Ω–æ {expected_order}, –æ–∂–∏–¥–∞–µ—Ç—Å—è {actual_order}")
        
        if errors:
            return False, f"–ö–†–ò–¢–ò–ß–ù–û - —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–º–ø—Ç–∞ –Ω–∞—Ä—É—à–µ–Ω–∞: {'; '.join(errors[:3])}"
        
        return True, ""
    
    def _check_russian_language(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞"""
        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
        cyrillic_chars = len(re.findall(r'[–∞-—è—ë]', text.lower()))
        total_letters = len(re.findall(r'[a-zA-Z–∞-—è—ë–ê-–Ø–Å]', text))
        
        if total_letters > 0:
            cyrillic_ratio = cyrillic_chars / total_letters
            if cyrillic_ratio < 0.8:
                return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {cyrillic_ratio:.2%} –∫–∏—Ä–∏–ª–ª–∏—Ü—ã"
        
        return True, ""
    
    def _check_no_source_mentions(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        source_keywords = [
            '–∏—Å—Ç–æ—á–Ω–∏–∫', '–¥–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã', '—Å–æ–≥–ª–∞—Å–Ω–æ', '–ø–æ –¥–∞–Ω–Ω—ã–º',
            'newsdata', 'prokerala', 'gemini', 'openai', 'api'
        ]
        
        text_lower = text.lower()
        found_sources = [word for word in source_keywords if word in text_lower]
        
        if found_sources:
            return False, f"–ù–∞–π–¥–µ–Ω—ã —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {found_sources}"
        
        return True, ""
    
    def _check_graphic_icons_not_bullets(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∏–∫–æ–Ω–æ–∫ –≤–º–µ—Å—Ç–æ –æ–±—ã—á–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤"""
        # –ò—â–µ–º –æ–±—ã—á–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
        bullet_patterns = [r'^\s*\*\s', r'^\s*-\s', r'^\s*‚Ä¢\s']
        found_bullets = []
        
        for pattern in bullet_patterns:
            matches = re.findall(pattern, text, re.MULTILINE)
            if matches:
                found_bullets.extend(matches)
        
        if found_bullets:
            return False, f"–ù–∞–π–¥–µ–Ω—ã –æ–±—ã—á–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –≤–º–µ—Å—Ç–æ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∏–∫–æ–Ω–æ–∫: {found_bullets[:3]}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∏–∫–æ–Ω–æ–∫ –∏–∑ prompts.py
        required_icons = ['‚≠ê', 'üéØ', 'üí´', '‚ö°', 'üî•', 'üíé', 'üöÄ', '‚ö†Ô∏è', 'üí∞']
        found_icons = [icon for icon in required_icons if icon in text]
        
        if len(found_icons) < 3:
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∏–∫–æ–Ω–æ–∫. –ù–∞–π–¥–µ–Ω–æ: {found_icons}, –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 3 –∏–∑ {required_icons}"
        
        return True, ""
    
    def _check_astro_symbols_usage(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        astro_symbols = ['‚ôà', '‚ôâ', '‚ôä', '‚ôã', '‚ôå', '‚ôç', '‚ôé', '‚ôè', '‚ôê', '‚ôë', '‚ôí', '‚ôì', '‚òâ', '‚òΩ', '‚òø', '‚ôÄ', '‚ôÇ', '‚ôÉ', '‚ôÑ', '‚õ¢', '‚ôÜ', '‚ôá']
        found_symbols = [symbol for symbol in astro_symbols if symbol in text]
        
        if len(found_symbols) < 2:
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤. –ù–∞–π–¥–µ–Ω–æ: {found_symbols}, –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2"
        
        return True, ""
    
    def _check_professional_tone(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–æ–Ω–∞"""
        # –ò—â–µ–º –Ω–µ–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã
        unprofessional_phrases = [
            '–∏–∑–≤–∏–Ω–∏—Ç–µ', '–ø—Ä–æ—Å—Ç–∏—Ç–µ', '–∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é', '–≤–æ–∑–º–æ–∂–Ω–æ', '–Ω–∞–≤–µ—Ä–Ω–æ–µ', '–º–æ–∂–µ—Ç –±—ã—Ç—å',
            '—è –¥—É–º–∞—é', '—è —Å—á–∏—Ç–∞—é', '–ø–æ –º–æ–µ–º—É –º–Ω–µ–Ω–∏—é'
        ]
        
        text_lower = text.lower()
        found_unprofessional = [phrase for phrase in unprofessional_phrases if phrase in text_lower]
        
        if found_unprofessional:
            return False, f"–ù–∞–π–¥–µ–Ω—ã –Ω–µ–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã: {found_unprofessional[:3]}"
        
        return True, ""
    
    def _check_no_direct_financial_advice(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ø—Ä—è–º—ã—Ö —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Å–æ–≤–µ—Ç–æ–≤"""
        direct_advice_patterns = [
            r'–ø–æ–∫—É–ø–∞–π—Ç–µ\s+–∞–∫—Ü–∏–∏', r'–ø—Ä–æ–¥–∞–≤–∞–π—Ç–µ\s+–∞–∫—Ü–∏–∏', r'–∏–Ω–≤–µ—Å—Ç–∏—Ä—É–π—Ç–µ\s+–≤',
            r'–∫—É–ø–∏—Ç–µ\s+', r'–ø—Ä–æ–¥–∞–π—Ç–µ\s+', r'–≤–ª–æ–∂–∏—Ç–µ\s+–¥–µ–Ω—å–≥–∏'
        ]
        
        text_lower = text.lower()
        found_advice = []
        
        for pattern in direct_advice_patterns:
            if re.search(pattern, text_lower):
                found_advice.append(pattern)
        
        if found_advice:
            return False, f"–ù–∞–π–¥–µ–Ω—ã –ø—Ä—è–º—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Å–æ–≤–µ—Ç—ã: {found_advice[:2]}"
        
        return True, ""
    
    def _check_news_context_usage(self, text: str) -> Tuple[bool, str]:
        """–ö–†–ò–¢–ò–ß–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, —É–∫–∞–∑—ã–≤–∞—é—â–∏–µ –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        news_indicators = [
            '—Å–æ–≥–ª–∞—Å–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º –Ω–æ–≤–æ—Å—Ç—è–º', '–ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏', '—Ç–µ–∫—É—â–∏–µ —Å–æ–±—ã—Ç–∏—è',
            '–Ω–æ–≤–æ—Å—Ç–∏ –æ', '—Å–æ–±—ã—Ç–∏—è –≤', '—Å–æ–≥–ª–∞—Å–Ω–æ –¥–∞–Ω–Ω—ã–º', '–ø–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏',
            '–Ω–µ–¥–∞–≤–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è', '–∞–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è', '—Ç–µ–∫—É—â–∞—è —Å–∏—Ç—É–∞—Ü–∏—è'
        ]
        
        text_lower = text.lower()
        found_indicators = [indicator for indicator in news_indicators if indicator in text_lower]
        
        if not found_indicators:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –Ω–æ–≤–æ—Å—Ç–∏
            modern_terms = [
                '—ç–∫–æ–Ω–æ–º–∏–∫–∞', '—Ä—ã–Ω–æ–∫', '–∏–Ω—Ñ–ª—è—Ü–∏—è', '—Å–∞–Ω–∫—Ü–∏–∏', '–∫—Ä–∏–∑–∏—Å', 
                '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', '—Ü–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏—è', 'AI', '–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç',
                'ESG', '—É—Å—Ç–æ–π—á–∏–≤–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ', '–≥–ª–æ–±–∞–ª–∏–∑–∞—Ü–∏—è'
            ]
            
            found_modern = [term for term in modern_terms if term in text_lower]
            
            if len(found_modern) < 2:
                return False, f"–ö–†–ò–¢–ò–ß–ù–û: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π. –ù–∞–π–¥–µ–Ω–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: {found_indicators}, —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤: {found_modern}"
        
        return True, f"–ù–∞–π–¥–µ–Ω—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {found_indicators[:3]}"
    
    def _check_company_examples(self, text: str) -> Tuple[bool, str]:
        """–ö–†–ò–¢–ò–ß–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π"""
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–º–ø–∞–Ω–∏–π
        company_patterns = [
            r'–∫–æ–º–ø–∞–Ω–∏[—è–∏]\s+[–ê-–Ø–Å][–∞-—è—ë]+',           # –∫–æ–º–ø–∞–Ω–∏—è Apple
            r'–±—Ä–µ–Ω–¥\s+[–ê-–Ø–Å][–∞-—è—ë]+',                # –±—Ä–µ–Ω–¥ Nike
            r'–∫–æ—Ä–ø–æ—Ä–∞—Ü–∏[—è–∏]\s+[–ê-–Ø–Å][–∞-—è—ë]+',        # –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏—è Microsoft
            r'–≥–∏–≥–∞–Ω—Ç\s+[–ê-–Ø–Å][–∞-—è—ë]+',               # –≥–∏–≥–∞–Ω—Ç Amazon
            r'[–ê-–Ø–Å][–∞-—è—ë]+\s+(?:Inc|LLC|Corp|Ltd)', # Apple Inc
            r'–∏–∑–≤–µ—Å—Ç–Ω[–∞—è].*[–ê-–Ø–Å][–∞-—è—ë]+',           # –∏–∑–≤–µ—Å—Ç–Ω–∞—è Tesla
        ]
        
        # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏ —Ä–∞–∑–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤ –∑–æ–¥–∏–∞–∫–∞
        famous_companies = [
            'apple', 'microsoft', 'google', 'amazon', 'tesla', 'meta', 'netflix',
            'nike', 'coca-cola', 'mcdonalds', 'starbucks', 'disney', 'bmw',
            'mercedes', 'volkswagen', 'toyota', 'samsung', 'sony', 'lg',
            'alibaba', 'tencent', 'baidu', 'xiaomi', 'huawei',
            '—Å–±–µ—Ä–±–∞–Ω–∫', '–≥–∞–∑–ø—Ä–æ–º', '–ª—É–∫–æ–π–ª', '—Ä–æ—Å–Ω–µ—Ñ—Ç', '—è–Ω–¥–µ–∫—Å', '–º—Ç—Å'
        ]
        
        text_lower = text.lower()
        found_companies = []
        
        # –ü–æ–∏—Å–∫ –ø—Ä—è–º—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π
        for company in famous_companies:
            if company in text_lower:
                found_companies.append(company)
        
        # –ü–æ–∏—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–π
        company_mentions = []
        for pattern in company_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            company_mentions.extend(matches[:3])  # –ù–µ –±–æ–ª–µ–µ 3 –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        
        total_examples = len(found_companies) + len(company_mentions)
        
        if total_examples < 2:
            return False, f"–ö–†–ò–¢–ò–ß–ù–û: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–º–ø–∞–Ω–∏–π. –ù–∞–π–¥–µ–Ω–æ: {found_companies[:3]} + {company_mentions[:3]} (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2-3 –ø—Ä–∏–º–µ—Ä–∞)"
        
        return True, f"–ù–∞–π–¥–µ–Ω—ã –ø—Ä–∏–º–µ—Ä—ã –∫–æ–º–ø–∞–Ω–∏–π: {found_companies[:3]} + {company_mentions[:3]}"
    
    def fix_text(self, text: str) -> str:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text (str): –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            str: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        # –£–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ HTML-—Ç–µ–≥–∏ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º <b> –∏ <i> –¥–ª—è Telegram)
        text = re.sub(r'<(?!/?[bi]>)[^>]+>', '', text)
        
        # –£–±–∏—Ä–∞–µ–º Markdown
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)  # **–∂–∏—Ä–Ω—ã–π**
        text = re.sub(r'__([^_]+)__', r'\1', text)      # __–∂–∏—Ä–Ω—ã–π__
        text = re.sub(r'\*([^*]+)\*', r'\1', text)      # *–∫—É—Ä—Å–∏–≤*
        text = re.sub(r'_([^_]+)_', r'\1', text)        # _–∫—É—Ä—Å–∏–≤_
        
        # –£–±–∏—Ä–∞–µ–º —Å–∏–º–≤–æ–ª—ã # –∏ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ —ç–º–æ–¥–∑–∏
        text = re.sub(r'^#{1,6}\s*(.+)$', r'üåü \1', text, flags=re.MULTILINE)
        text = re.sub(r'###\s*(.+)', r'üíé \1', text)
        text = re.sub(r'##\s*(.+)', r'üöÄ \1', text)
        text = re.sub(r'#\s*(.+)', r'‚≠ê \1', text)
        
        # –ó–∞–º–µ–Ω—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
        text = re.sub(r'^---+$', '', text, flags=re.MULTILINE)
        text = re.sub(r'^===+$', '', text, flags=re.MULTILINE)
        
        # –£–±–∏—Ä–∞–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        text = re.sub(r'(–∏—Å—Ç–æ—á–Ω–∏–∫|–¥–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã|—Å–æ–≥–ª–∞—Å–Ω–æ|–ø–æ –¥–∞–Ω–Ω—ã–º)', '', text, flags=re.IGNORECASE)
        text = re.sub(r'(newsdata|prokerala|gemini|openai|api)', '', text, flags=re.IGNORECASE)
        
        # –ó–∞–º–µ–Ω—è–µ–º –æ–±—ã—á–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –Ω–∞ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∏–∫–æ–Ω–∫–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏—Ö –µ—â–µ –Ω–µ—Ç)
        text = re.sub(r'^\s*\*\s+(?!‚≠ê|üí´|üéØ|‚ö°|üî•|üíé|üöÄ|‚ö†Ô∏è|üí∞)(.+)', r'‚≠ê \1', text, flags=re.MULTILINE)
        text = re.sub(r'^\s*-\s+(?!‚≠ê|üí´|üéØ|‚ö°|üî•|üíé|üöÄ|‚ö†Ô∏è|üí∞)(.+)', r'üí´ \1', text, flags=re.MULTILINE)
        text = re.sub(r'^\s*‚Ä¢\s+(?!‚≠ê|üí´|üéØ|‚ö°|üî•|üíé|üöÄ|‚ö†Ô∏è|üí∞)(.+)', r'üéØ \1', text, flags=re.MULTILINE)
        
        # –£–±–∏—Ä–∞–µ–º –Ω–µ–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã
        unprofessional_replacements = {
            '–∏–∑–≤–∏–Ω–∏—Ç–µ': '', '–ø—Ä–æ—Å—Ç–∏—Ç–µ': '', '–∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é': '',
            '–≤–æ–∑–º–æ–∂–Ω–æ': '–≤–µ—Ä–æ—è—Ç–Ω–æ', '–Ω–∞–≤–µ—Ä–Ω–æ–µ': '—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ', '–º–æ–∂–µ—Ç –±—ã—Ç—å': '–≤–µ—Ä–æ—è—Ç–Ω–æ',
            '—è –¥—É–º–∞—é': '', '—è —Å—á–∏—Ç–∞—é': '', '–ø–æ –º–æ–µ–º—É –º–Ω–µ–Ω–∏—é': ''
        }
        
        for phrase, replacement in unprofessional_replacements.items():
            text = re.sub(phrase, replacement, text, flags=re.IGNORECASE)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ 6 –±–ª–æ–∫–æ–≤ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        if 'üåü' not in text or '–í–õ–ò–Ø–ù–ò–ï –ó–ù–ê–ö–ê –ó–û–î–ò–ê–ö–ê' not in text:
            text = 'üåü –í–õ–ò–Ø–ù–ò–ï –ó–ù–ê–ö–ê –ó–û–î–ò–ê–ö–ê –ù–ê –°–£–î–¨–ë–£ –ö–û–ú–ü–ê–ù–ò–ò\n\n' + text
        if 'üîÆ' not in text or '–í–õ–ò–Ø–ù–ò–ï –ü–õ–ê–ù–ï–¢' not in text:
            text = text + '\n\nüîÆ –í–õ–ò–Ø–ù–ò–ï –ü–õ–ê–ù–ï–¢ –ò –ú–ï–°–¢–ê –†–ï–ì–ò–°–¢–†–ê–¶–ò–ò'
        if 'üíé' not in text or '–°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´' not in text:
            text = text + '\n\nüíé –°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´ –ò –ü–û–¢–ï–ù–¶–ò–ê–õ –†–û–°–¢–ê'
        if 'üßò' not in text or '–§–ò–õ–û–°–û–§–°–ö–ê–Ø –ö–û–ù–¶–ï–ü–¶–ò–Ø' not in text:
            text = text + '\n\nüßò –§–ò–õ–û–°–û–§–°–ö–ê–Ø –ö–û–ù–¶–ï–ü–¶–ò–Ø –ö–û–ú–ü–ê–ù–ò–ò'
        if '‚ö†Ô∏è' not in text or '–ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ï –†–ò–°–ö–ò' not in text:
            text = text + '\n\n‚ö†Ô∏è –ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ï –†–ò–°–ö–ò –ò –í–´–ó–û–í–´'
        if 'üíº' not in text or '–ë–ò–ó–ù–ï–°-–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò' not in text:
            text = text + '\n\nüíº –ë–ò–ó–ù–ï–°-–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ò –°–¢–†–ê–¢–ï–ì–ò–ò'
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –º–µ–∂–¥—É —Ä–∞–∑–¥–µ–ª–∞–º–∏ —Å —ç–º–æ–¥–∑–∏
        text = re.sub(r'(\n)(üåü|üíé|üöÄ|‚ö†Ô∏è|üìà|üîÆ|üíº|üéØ|üí°|‚ú®)', r'\1\n\2', text)
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø–µ—Ä–µ–Ω–æ—Å—ã
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
        
        return text.strip()


class ValidationAgent:
    """–ê–≥–µ–Ω—Ç –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ —Å RLHF"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Anthropic –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π
        try:
            from validation_agent.claude_validator import AnthropicValidationAgent
            self.claude_agent = AnthropicValidationAgent()
            self.use_claude = True
            logger.info("‚úÖ Anthropic –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            logger.warning("‚ö†Ô∏è Anthropic –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: %s", str(e))
            # –†–µ–∑–µ—Ä–≤–Ω—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π –≤–∞–ª–∏–¥–∞—Ç–æ—Ä
            self.validator = PromptValidator()
            self.use_claude = False
            logger.info("‚úÖ –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    async def validate_and_fix(self, text: str, analysis_type: str = "zodiac", original_prompt: str = "") -> str:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –º–∏–Ω–∏–º—É–º 7 –±–∞–ª–ª–æ–≤
        
        Args:
            text (str): –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            analysis_type (str): –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞
            original_prompt (str): –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            
        Returns:
            str: –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        try:
            if self.use_claude and hasattr(self, 'claude_agent'):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º Anthropic –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π
                logger.info("ü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ–º Anthropic –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–ª—è %s (—Ü–µ–ª—å: 7+ –±–∞–ª–ª–æ–≤)", analysis_type)
                
                # –°–¢–†–ï–ú–ò–ú–°–Ø –ö –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ô –û–¶–ï–ù–ö–ï 10 –ë–ê–õ–õ–û–í
                logger.info("üéØ –¶–ï–õ–¨: –¥–æ—Å—Ç–∏—á—å –æ—Ü–µ–Ω–∫–∏ 10.0/10 (—Å—Ç—Ä–µ–º–∏–º—Å—è –∫ —Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤—É)")
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é —á–µ—Ä–µ–∑ Claude —Å –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–º —É–ª—É—á—à–µ–Ω–∏–µ–º
                improved_text = await self.claude_agent.validate_and_fix(
                    text=text,
                    analysis_type=analysis_type,
                    original_prompt=original_prompt
                )
                
                # –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É
                final_result = await self.claude_agent.claude_validator.validate_and_score(
                    improved_text, original_prompt, analysis_type
                )
                final_score = final_result.get('score', 7.0)
                logger.info("üèÜ Anthropic –≤–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: %.1f/10", final_score)
                return improved_text
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞–ª–∏–¥–∞—Ç–æ—Ä
                logger.info("üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–ª—è %s", analysis_type)
                return await self._fallback_validation(text, analysis_type, original_prompt)
                
        except Exception as e:
            logger.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: %s", str(e))
            logger.error("Stacktrace: %s", traceback.format_exc())
            # –í–°–ï–ì–î–ê –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ö–æ—Ç—è –±—ã –±–∞–∑–æ–≤—É—é –æ—á–∏—Å—Ç–∫—É
            return self._basic_cleanup(text)
    
    def _basic_cleanup(self, text: str) -> str:
        """–ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        if not text:
            return "–ê–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        text = re.sub(r'<(?!/?[bi]>)[^>]+>', '', text)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ HTML
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã
        
        return text.strip()
    
    async def _fallback_validation(self, text: str, analysis_type: str, original_prompt: str) -> str:
        """–†–µ–∑–µ—Ä–≤–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Claude"""
        import asyncio
        
        if not hasattr(self, 'validator'):
            self.validator = PromptValidator()
        
        current_text = text
        max_iterations = 2  # –£–º–µ–Ω—å—à–∞–µ–º –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
        iteration = 0
        
        logger.info("üîç –†–µ–∑–µ—Ä–≤–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Ç–∏–ø–∞ '%s'", analysis_type)
        
        while iteration < max_iterations:
            iteration += 1
            logger.info("üîÑ –ò—Ç–µ—Ä–∞—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ #%d", iteration)
            
            # –õ–æ–∫–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
            is_valid_local, local_errors = self.validator.validate_text(current_text, analysis_type)
            
            if is_valid_local:
                logger.info("‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ %d –∏—Ç–µ—Ä–∞—Ü–∏–π", iteration)
                return current_text
            
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
            current_text = self.validator.fix_text(current_text)
            logger.info("üîß –¢–µ–∫—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ (–∏—Ç–µ—Ä–∞—Ü–∏—è %d)", iteration)
            
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏
            if iteration < max_iterations:
                await asyncio.sleep(0.1)
        
        return current_text
    
    async def validate_and_fix_with_feedback(self, 
                                           text: str, 
                                           analysis_type: str = "zodiac", 
                                           original_prompt: str = "",
                                           generation_function=None,
                                           generation_params: Optional[Dict[str, Any]] = None) -> Tuple[str, Dict[str, Any]]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
        
        Args:
            text (str): –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            analysis_type (str): –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞
            original_prompt (str): –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            generation_function: –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            generation_params (Dict): –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            Tuple[str, Dict]: (—É–ª—É—á—à–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –¥–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏)
        """
        logger.info("üîß –ó–ê–ü–£–°–ö –í–ê–õ–ò–î–ê–¶–ò–ò –° –û–ë–†–ê–¢–ù–û–ô –°–í–Ø–ó–¨–Æ –î–õ–Ø –û–°–ù–û–í–ù–û–ì–û –ê–ì–ï–ù–¢–ê")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É
        is_valid, error_list = self.validate_text(text, analysis_type)
        score = max(1.0, 10.0 - sum([self._get_penalty_for_rule(err.split(' ')[0]) for err in error_list]))
        
        # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
        feedback_report = {
            'current_score': round(score, 1),
            'is_valid': is_valid,
            'target_score': 10.0,
            'critical_errors': [err for err in error_list if any(rule in err for rule in 
                               ['no_html_tags', 'no_markdown', 'required_emoji_sections', 'news_context_usage'])],
            'moderate_errors': [err for err in error_list if err not in [err for err in error_list if any(rule in err for rule in 
                               ['no_html_tags', 'no_markdown', 'required_emoji_sections', 'news_context_usage'])]],
            'missing_requirements': self._identify_missing_requirements(text),
            'formatting_issues': self._identify_formatting_issues(text),
            'content_gaps': self._identify_content_gaps(text),
        }
        
        logger.info("üìä –û–¢–ß–ï–¢ –î–õ–Ø –û–°–ù–û–í–ù–û–ì–û –ê–ì–ï–ù–¢–ê:")
        logger.info("üéØ –¢–µ–∫—É—â–∞—è –æ—Ü–µ–Ω–∫–∞: %.1f/10 (—Ü–µ–ª—å: 10.0)", score)
        logger.info("ÔøΩ –ö—Ä–∏—Ç–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏: %d", len(feedback_report['critical_errors']))
        logger.info("‚ö†Ô∏è –£–º–µ—Ä–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏: %d", len(feedback_report['moderate_errors']))
        
        if score >= 10.0:
            logger.info("üéâ –û–°–ù–û–í–ù–û–ô –ê–ì–ï–ù–¢ –î–û–°–¢–ò–ì –°–û–í–ï–†–®–ï–ù–°–¢–í–ê!")
            return text, feedback_report
        elif score >= 7.0:
            logger.info("‚úÖ –û—Å–Ω–æ–≤–Ω–æ–π –∞–≥–µ–Ω—Ç –¥–æ—Å—Ç–∏–≥ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞, –Ω–æ –º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –¥–æ 10.0")
        else:
            logger.warning("‚ùå –û–°–ù–û–í–ù–û–ô –ê–ì–ï–ù–¢ –î–û–õ–ñ–ï–ù –ö–†–ò–¢–ò–ß–ï–°–ö–ò –£–õ–£–ß–®–ò–¢–¨ –†–ê–ë–û–¢–£")
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ñ—É–Ω–∫—Ü–∏—è —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë —Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é
        if generation_function and generation_params and score < 8.0:
            logger.info("üîÑ –ó–ê–ü–†–ê–®–ò–í–ê–ï–ú –†–ï–ì–ï–ù–ï–†–ê–¶–ò–Æ –£ –û–°–ù–û–í–ù–û–ì–û –ê–ì–ï–ù–¢–ê –° –£–ß–ï–¢–û–ú –û–®–ò–ë–û–ö")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–∞—Ö –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            enhanced_params = generation_params.copy()
            enhanced_params['validation_feedback'] = feedback_report
            enhanced_params['improvement_instructions'] = self._create_improvement_instructions(feedback_report)
            
            try:
                improved_text = await generation_function(**enhanced_params)
                if improved_text and len(improved_text.strip()) > 500:
                    # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                    is_improved, new_errors = self.validate_text(improved_text, analysis_type)
                    new_score = max(1.0, 10.0 - sum([self._get_penalty_for_rule(err.split(' ')[0]) for err in new_errors]))
                    
                    if new_score > score:
                        logger.info("üìà –û–°–ù–û–í–ù–û–ô –ê–ì–ï–ù–¢ –£–õ–£–ß–®–ò–õ –†–ï–ó–£–õ–¨–¢–ê–¢: %.1f ‚Üí %.1f", score, new_score)
                        feedback_report['current_score'] = round(new_score, 1)
                        feedback_report['improvement'] = round(new_score - score, 1)
                        return improved_text, feedback_report
                    else:
                        logger.warning("üìâ –†–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ —É–ª—É—á—à–∏–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç: %.1f vs %.1f", new_score, score)
            except Exception as e:
                logger.error("‚ùå –û—à–∏–±–∫–∞ —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: %s", str(e))
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        improved_text = await self.validate_and_fix(text, analysis_type, original_prompt)
        return improved_text, feedback_report
    
    def _identify_missing_requirements(self, text: str) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏–∑ –ø—Ä–æ–º–ø—Ç–∞"""
        missing = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –±–ª–æ–∫–æ–≤
        required_emojis = ['üåü', 'üîÆ', 'üíé', 'üßò', '‚ö†Ô∏è', 'üíº']
        for emoji in required_emojis:
            if emoji not in text:
                missing.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±–ª–æ–∫ —Å —ç–º–æ–¥–∑–∏ {emoji}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if '–Ω–æ–≤–æ—Å—Ç' not in text.lower() and '—Å–æ–±—ã—Ç' not in text.lower():
            missing.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–º–ø–∞–Ω–∏–π
        company_keywords = ['–∫–æ–º–ø–∞–Ω–∏', '–∫–æ—Ä–ø–æ—Ä–∞—Ü–∏', '–±—Ä–µ–Ω–¥', 'apple', 'microsoft', 'google']
        if not any(keyword in text.lower() for keyword in company_keywords):
            missing.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∏–º–µ—Ä—ã –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π")
            
        return missing
    
    def _identify_formatting_issues(self, text: str) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        issues = []
        
        # HTML —Ç–µ–≥–∏
        if re.search(r'<[^>]+>', text):
            issues.append("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã HTML-—Ç–µ–≥–∏ (–∑–∞–ø—Ä–µ—â–µ–Ω—ã –¥–ª—è Telegram)")
        
        # Markdown
        if re.search(r'\*\*[^*]+\*\*|__[^_]+__|^#{1,6}\s', text, re.MULTILINE):
            issues.append("–û–±–Ω–∞—Ä—É–∂–µ–Ω Markdown (–∑–∞–ø—Ä–µ—â–µ–Ω –¥–ª—è Telegram)")
        
        # –û–±—ã—á–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
        if re.search(r'^\s*[\*\-‚Ä¢]\s', text, re.MULTILINE):
            issues.append("–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –æ–±—ã—á–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –≤–º–µ—Å—Ç–æ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∏–∫–æ–Ω–æ–∫")
            
        return issues
    
    def _identify_content_gaps(self, text: str) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–æ–±–µ–ª—ã –≤ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏"""
        gaps = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—ä–µ–º–∞
        word_count = len(text.split())
        if word_count < 1500:
            gaps.append(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –æ–±—ä–µ–º: {word_count} —Å–ª–æ–≤ (–Ω—É–∂–Ω–æ 1500+)")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        astro_symbols = ['‚ôà', '‚ôâ', '‚ôä', '‚ôã', '‚ôå', '‚ôç', '‚ôé', '‚ôè', '‚ôê', '‚ôë', '‚ôí', '‚ôì']
        if not any(symbol in text for symbol in astro_symbols):
            gaps.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —ç–º–æ–¥–∑–∏
        emoji_count = len(re.findall(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002600-\U000027BF\U0001F900-\U0001F9FF]', text))
        if emoji_count < 10:
            gaps.append(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —ç–º–æ–¥–∑–∏: {emoji_count} (–Ω—É–∂–Ω–æ 10+)")
            
        return gaps
    
    def _create_improvement_instructions(self, feedback: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
        instructions = []
        
        instructions.append(f"–¢–ï–ö–£–©–ê–Ø –û–¶–ï–ù–ö–ê: {feedback['current_score']}/10")
        instructions.append(f"–¶–ï–õ–¨: –î–û–°–¢–ò–ß–¨ 10.0/10 –ë–ê–õ–õ–û–í")
        
        if feedback['critical_errors']:
            instructions.append("üö® –ö–†–ò–¢–ò–ß–ù–´–ï –û–®–ò–ë–ö–ò (–∏—Å–ø—Ä–∞–≤—å –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û):")
            for error in feedback['critical_errors'][:5]:
                instructions.append(f"  - {error}")
        
        if feedback['missing_requirements']:
            instructions.append("üìã –û–¢–°–£–¢–°–¢–í–£–Æ–©–ò–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:")
            for req in feedback['missing_requirements']:
                instructions.append(f"  - {req}")
        
        if feedback['formatting_issues']:
            instructions.append("üé® –ü–†–û–ë–õ–ï–ú–´ –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–Ø:")
            for issue in feedback['formatting_issues']:
                instructions.append(f"  - {issue}")
        
        instructions.append("üí° –ö–õ–Æ–ß–ï–í–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø –î–õ–Ø –û–¶–ï–ù–ö–ò 10/10:")
        instructions.append("  - –í–°–ï 6 –±–ª–æ–∫–æ–≤ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —ç–º–æ–¥–∑–∏")
        instructions.append("  - –ù–ò–ö–ê–ö–ò–• HTML-—Ç–µ–≥–æ–≤ –∏–ª–∏ Markdown")
        instructions.append("  - –ü—Ä–∏–º–µ—Ä—ã 2-3 –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π")
        instructions.append("  - –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ")
        instructions.append("  - –ú–∏–Ω–∏–º—É–º 1500 —Å–ª–æ–≤ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
        
        return "\n".join(instructions)
