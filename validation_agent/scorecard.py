# -*- coding: utf-8 -*-
from typing import Dict, List
from .section_parser import split_sections, word_count, has_markdown_or_html

def compute_score(text: str, profile: dict) -> Dict:
    prof = profile["profile"]
    glob = profile["global"]
    min_words = prof.get("min_words_per_section", 0)
    sections_cfg = prof["sections"]
    expected_titles = [x["title"] for x in sections_cfg]

    # —Ñ–æ—Ä–º–∞—Ç
    critical_broken = has_markdown_or_html(text)

    sections_found = split_sections(text, expected_titles)
    score = 0.0
    breakdown = []

    # —Å–µ–∫—Ü–∏–∏: –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ –∏ –∫–∞—á–µ—Å—Ç–≤–æ
    for sec in sections_cfg:
        title = sec["title"]
        presence = sec.get("presence", 0.0)
        quality = sec.get("quality", 0.0)
        body = sections_found.get(title, "")
        present_ok = 1.0 if body else 0.0
        quality_ok = 1.0 if (body and word_count(body) >= min_words) else 0.0
        pts = presence * present_ok + quality * quality_ok
        score += pts
        breakdown.append({
            "section": title,
            "present": bool(present_ok),
            "quality_ok": bool(quality_ok),
            "words": word_count(body) if body else 0,
            "points": pts
        })

    # extra –∫—Ä–∏—Ç–µ—Ä–∏–∏
    extra_pts = 0.0
    extras = prof.get("extra", {})
    if extras.get("known_companies") and "üè¢" in "".join(sections_found.keys()):
        extra_pts += extras["known_companies"]
    if extras.get("industry_binding"):
        # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –≤ —Ç–µ–∫—Å—Ç–µ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —Å–ª–æ–≤–æ "–æ—Ç—Ä–∞—Å–ª" –∏–ª–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –æ—Ç—Ä–∞—Å–ª–∏ –æ—Ç –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if "–æ—Ç—Ä–∞—Å–ª" in text.lower():
            extra_pts += extras["industry_binding"]
    if extras.get("status_binding"):
        # –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏: –∏—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Å—Ç–∞—Ç—É—Å–∞
        if any(w in text.lower() for w in ["—Å–æ—Ç—Ä—É–¥–Ω–∏–∫", "–ø–∞—Ä—Ç–Ω–µ—Ä", "–∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç", "–∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–º"]):
            extra_pts += extras["status_binding"]
    if extras.get("news_2_2_2"):
        # –ø—Ä–∏–º–∏—Ç–∏–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –Ω–∞–π–¥–µ–Ω—ã —Ç—Ä–∏ –±–ª–æ–∫–∞ "–ü–æ–ª–∏—Ç–∏–∫–∞", "–≠–∫–æ–Ω–æ–º–∏–∫–∞", "–§–æ–Ω–¥–æ–≤—ã–π —Ä—ã–Ω–æ–∫"
        key_ok = all(k in text for k in ["–ü–æ–ª–∏—Ç–∏–∫–∞:", "–≠–∫–æ–Ω–æ–º–∏–∫–∞:", "–§–æ–Ω–¥–æ–≤—ã–π —Ä—ã–Ω–æ–∫:"])
        if key_ok:
            extra_pts += extras["news_2_2_2"]

    score += extra_pts

    # global –∫—Ä–∏—Ç–µ—Ä–∏–∏
    global_pts = 0.0
    tone_points = glob.get("tone_professional", {}).get("points", 0.0)
    fmt_points = glob.get("formatting_headers", {}).get("points", 0.0)
    if fmt_points:
        # —Å—á–∏—Ç–∞—è, —á—Ç–æ –Ω–∞–ª–∏—á–∏–µ –æ–∂–∏–¥–∞–µ–º—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —É–∂–µ –¥–∞—ë—Ç –æ—á–∫–∏
        global_pts += fmt_points
    if tone_points:
        # —É–ø—Ä–æ—â—ë–Ω–Ω–æ: –µ—Å–ª–∏ –Ω–µ—Ç –ø—Ä–æ—Å—Ç–æ—Ä–µ—á–Ω—ã—Ö –æ–±–æ—Ä–æ—Ç–æ–≤ ‚Äî –¥–∞—ë–º –æ—á–∫–∏ (—ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
        if not any(w in text.lower() for w in ["—ç—ç—ç", "–Ω—É", "—Ç–∏–ø–∞"]):
            global_pts += tone_points

    # –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∫—Ä–∏—Ç–µ—Ä–∏–π
    if glob.get("no_markdown_html", {}).get("critical", False) and has_markdown_or_html(text):
        # –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–≤–∞–ª ‚Äî –º–æ–∂–Ω–æ –∂—ë—Å—Ç–∫–æ –∑–∞–Ω—É–ª–∏—Ç—å
        final = max(0.0, score + global_pts - 5.0)
        return {
            "score": round(final, 2),
            "critical": True,
            "reason": "–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã HTML/Markdown –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏",
            "breakdown": breakdown,
            "extras": round(extra_pts, 2),
            "global": round(global_pts, 2)
        }

    final = round(score + global_pts, 2)
    return {
        "score": final,
        "critical": False,
        "breakdown": breakdown,
        "extras": round(extra_pts, 2),
        "global": round(global_pts, 2)
    }
